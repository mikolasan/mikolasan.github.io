{"componentChunkName":"component---src-templates-blog-template-js","path":"/ai/negative-training","result":{"data":{"markdownRemark":{"html":"<p>Negative lessons are very important. And they supposed to be stored very specifically in its own categories. These categories will provide only negative feedback during inference obviously.<br>\nStandard ANNs allow mixed weights but they heavily rely on gradient descent to keep the process stable.</p>\n<p>In ANNs those random negative weights don’t really make sense. They cannot have “reasoning” about what part of the signal should be suppressed. Maybe it could get such adjustments from the back propagation. But how often in order to produce a strong memory? We don’t create training sets with negative expectations.</p>\n<p>We can consider fully unsupervised learning where the negative observation will just go to another category. But that category would never have a color of undesirable event/object. In the recent Reinforcement Learning development researchers, indeed, try to give “colors” to such undesirable categories (maybe vectors or areas in the latent space).</p>\n<p>So this is about the propagation in neural networks I think this happens not with numbers, but with matrices not with derivatives I think it happens with the areas where when signal tries to go forward, it’s not continue. It’s not passing the neuron so it stops there. some negative I don’t know let’s call it energy and when that reaches threshold, some controller that knows about all neurons sees that and send back and as a signal to start making connections to altering connections and affect many neurons in that area I think it’s just chemical process there that affect not one single neuron but many of them, so then when the same signal repeats now it will make some new connections to appear there. Maybe it will take some time before you right or will.</p>\n<p>So in similar way, it works with excitation when when you pass when signal finds a new path that’s where to confirm it. This dopamine is sprinkled so we feel this emotion that last for sometime and for this time that connection improves so it finds a new path and maybe something happens with the old one maybe the boss still work but to confirm the new one it releases this chemicals, and that’s how new Francis established</p>","excerpt":"Negative lessons are very important. And they supposed to be stored very specifically in its own categories. These categories will provide…","tableOfContents":"","fields":{"socialcard":"gatsby-plugin-social-card/8bdcd2d5-dd95-5f5b-b1d6-49a931e2c290.jpg"},"frontmatter":{"date":"December 07, 2024","published":"December 07, 2024","lastModified":"December 07, 2024","title":"Negative training","subtitle":null,"section":null,"draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/negative-training.md","url":"/ai/negative-training","next":{"excerpt":"I always return back to this challenge. First I want to look at the correlation between columns Related: Is it always valid to use…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/titanic-kaggle-challenge.md","frontmatter":{"title":"Titanic","date":"2025-03-25T00:00:00.000Z","topic":null,"article":"quest"},"id":"aae8ea55-6c30-57eb-b327-abc2ca7c65ea"},"previous":{"excerpt":"Ref: Modeling of Hippocampus Together with Neocortex for Few-Shot Learning by Gideon Kowadlo from Cerenaut.ai DG I have a layer that…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/hippocampus-model.md","frontmatter":{"title":"Modelling of Hippocampus","date":"2024-10-01T00:00:00.000Z","topic":null,"article":"main"},"id":"5852ce15-bb47-5444-9198-3420aca715e0"},"recentArticles":[{"excerpt":"BAM can link together data of different types. Associations...  From one side the model requires to use bipolar patterns - arrays of -1 and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/bidirectional-associative-memories.md","frontmatter":{"title":"Bidirectional Associative Memories","date":null,"topic":true,"article":null},"id":"3ae9ac87-4c8b-5f18-8f19-ee1091111f95"},{"excerpt":"Phenotypic variation of transcriptomic cell types in mouse motor cortex (paper). Scientist got neurons from different layers and regions and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/brain-map.md","frontmatter":{"title":"Brain map","date":null,"topic":true,"article":null},"id":"f4152a9b-6747-5178-aea3-0de2e3f70b04"},{"excerpt":"Neural networks with biologically plausible accounts of neurogenesis they start with a minimal topology (just input and output unit) and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cascade-correlation-neural-networks.md","frontmatter":{"title":"Cascade Correlation Neural Networks","date":null,"topic":true,"article":null},"id":"1ba88be8-cdba-50c0-a9ba-c4a082ef60e7"},{"excerpt":"ACT-R CLARION LIDA Soar (code)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cognitive-architecture.md","frontmatter":{"title":"Cognitive Architecture","date":null,"topic":true,"article":null},"id":"1acc6cfc-d238-53b6-aeed-1207dd3b1d89"},{"excerpt":"Main paper PDF stacking lstms https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms intro to…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/long-short-term-memory.md","frontmatter":{"title":"Long Short-Term Memory","date":null,"topic":true,"article":null},"id":"a677bfb4-f49d-559c-8957-86db6eb41bda"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}