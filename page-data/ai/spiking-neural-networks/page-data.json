{"componentChunkName":"component---src-templates-blog-template-js","path":"/ai/spiking-neural-networks","result":{"data":{"markdownRemark":{"html":"<p>Better than any words, you can get an idea how SNNs work from <a href=\"https://youtu.be/3JQ3hYko51Y?t=122\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">this animation</a>.</p>\n<p>But here's a downside:</p>\n<blockquote>\n<p>...in order to reach accuracy of its ANN counterpart,\nit usually requires long spike trains to ensure the accuracy.\nTraditionally, a spike train needs around one thousand time steps to approach similar accuracy as its ANN counterpart</p>\n<p><em><a href=\"https://arxiv.org/pdf/2105.06943.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Efficient Spiking Neural Networks with Radix Encoding</a></em></p>\n</blockquote>\n<ul>\n<li><a href=\"http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx/ml2a/td2a_mlplus_snn.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx/ml2a/td2a_mlplus_snn.html</a></li>\n<li>A minimal sNN network <a href=\"https://thesai.org/Downloads/IJARAI/Volume4No7/Paper_1-A_Minimal_Spiking_Neural_Network_to_Rapidly_Train.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://thesai.org/Downloads/IJARAI/Volume4No7/Paper_1-A_Minimal_Spiking_Neural_Network_to_Rapidly_Train.pdf</a></li>\n<li>online book <a href=\"https://neuronaldynamics.epfl.ch/online/Ch7.S1.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://neuronaldynamics.epfl.ch/online/Ch7.S1.html</a></li>\n<li>Local connectivity and synaptic dynamics in mouse and human neocortex <a href=\"https://www.science.org/stoken/author-tokens/ST-374/full\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://www.science.org/stoken/author-tokens/ST-374/full</a></li>\n</ul>\n<h2 id=\"implementation\" style=\"position:relative;\">Implementation<a href=\"#implementation\" aria-label=\"implementation permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>How to write a spiking neural network simulation from scratch in Python</p>\n<ul>\n<li>Izhikevich model, Tensorflow <a href=\"https://github.com/kaizouman/tensorsandbox/blob/master/snn/simple_spiking_model.ipynb\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://github.com/kaizouman/tensorsandbox/blob/master/snn/simple_spiking_model.ipynb</a></li>\n<li>SpykeTorch ? <a href=\"https://github.com/miladmozafari/SpykeTorch\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://github.com/miladmozafari/SpykeTorch</a></li>\n<li>snnTorch <a href=\"https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_3.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_3.html</a> (<a href=\"https://arxiv.org/pdf/2109.12894.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">white paper</a>)</li>\n<li>Guillaume Chevalier's experiment <a href=\"https://guillaume-chevalier.com/spiking-neural-network-snn-with-pytorch-where-backpropagation-engenders-stdp-hebbian-learning/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">in his blog</a></li>\n<li><a href=\"https://github.com/dacorvo/tensorsandbox/blob/master/snn/simple_spiking_model.ipynb\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Notebook</a> simulating spiking neurons with Tensorflow</li>\n<li><a href=\"https://uwspace.uwaterloo.ca/bitstream/handle/10012/6122/Bobier_Bruce.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">The Attentional Routing Circuit</a> by Bobier</li>\n<li>Eliasmith and <a href=\"https://xchoo.github.io/spaun2.0/videos.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Spaun</a> model. Original article from <a href=\"https://www.science.org/doi/10.1126/science.1225266\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Science</a>. <a href=\"https://compneuro.uwaterloo.ca/files/publications/eliasmith.2012.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">PDF version</a>. And supplementary materials for <a href=\"https://www.science.org/action/downloadSupplement?doi=10.1126%2Fscience.1225266&#x26;file=1225266.eliasmith.sm.pdf#page91\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">A Large-Scale Model of the Functioning Brain</a>. Main technique is called <a href=\"\">Neural Engineering Framework</a>. And how memory works is explained <a href=\"https://www.jneurosci.org/content/26/14/3667\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">here</a> (reference 26 from supplementary materials). Which maybe needs one more step into <a href=\"https://www.researchgate.net/publication/11247971_Model_for_a_robust_neural_integrator\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">neural integrators</a>. Though I started with Hypervectors and Hyper Dimensional Computing reviewed in two articles (<a href=\"https://arxiv.org/pdf/2111.06077.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">part 1</a>, <a href=\"https://arxiv.org/pdf/2112.15424.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">part 2</a>) which actually led me to <a href=\"https://redwood.berkeley.edu/wp-content/uploads/2021/08/Neubert2019_Article_AnIntroductionToHyperdimension.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">An Introduction to Hyperdimensional Computing for Robotics</a> where for image recognition task they take intermediate layers of CNN networks and operate on big dimension vectors</li>\n</ul>\n<h2 id=\"training-methods\" style=\"position:relative;\">Training methods<a href=\"#training-methods\" aria-label=\"training methods permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>A list from <a href=\"https://cnvrg.io/spiking-neural-networks/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">this blog</a></p>\n<h3 id=\"unsupervised-learning\" style=\"position:relative;\">Unsupervised Learning<a href=\"#unsupervised-learning\" aria-label=\"unsupervised learning permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h3>\n<ul>\n<li><a href=\"http://www.scholarpedia.org/article/Spike-timing_dependent_plasticity\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Spike-timing-dependent plasticity (STDP)</a></li>\n<li><a href=\"https://arxiv.org/pdf/1807.09374.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Unsupervised Learning with Self-Organizing Spiking Neural Networks</a> (Hazan et al 2018). Growing Spiking Neural Networks, activation based on spacial proximity which makes similar classes transition from one to another.</li>\n<li><a href=\"https://www.sciencedirect.com/science/article/abs/pii/016622369390081V\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Artola, Br√∂cher, Singer (ABS) rule</a></li>\n<li><a href=\"http://www.scholarpedia.org/article/BCM_theory\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Bienenstock, Cooper, Munro (BCM) rule</a></li>\n<li><a href=\"http://www.izhikevich.org/publications/bcm.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Relationship between BCM and STDP rules</a></li>\n</ul>\n<h3 id=\"supervised-learning\" style=\"position:relative;\">Supervised Learning<a href=\"#supervised-learning\" aria-label=\"supervised learning permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h3>\n<ul>\n<li><a href=\"https://www.researchgate.net/publication/221165220_SpikeProp_backpropagation_for_networks_of_spiking_neurons\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">SpikeProp</a></li>\n<li><a href=\"http://d1.cie.put.poznan.pl/pracownicy/prac_15/Publikacje/ReSuMe_FP_TechRep_2005a.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Remote Supervised Method (ReSuMe)</a></li>\n<li><a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.5637&#x26;rep=rep1&#x26;type=pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">FreqProp</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Leabra\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Local error-driven associative biologically realistic algorithm (LEABRA)</a></li>\n<li><a href=\"http://ecee.colorado.edu/~ecen4831/Demuth/Ch7_pres.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Supervised Hebbian Learning</a></li>\n</ul>\n<h3 id=\"reinforcement-learning\" style=\"position:relative;\">Reinforcement Learning<a href=\"#reinforcement-learning\" aria-label=\"reinforcement learning permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h3>\n<ul>\n<li><a href=\"https://www.semanticscholar.org/paper/A-Spiking-Neural-Network-Model-of-an-Actor-Critic-Potjans-Morrison/dee121c5fb8b74c7c37b953ffabd73c16cb216ab\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Spiking Actor-Critic method</a> \"A Spiking Neural Network Model of an Actor-Critic Learning Agent\" by Wiebke Potjans, A. Morrison, M. Diesmann (2008)</li>\n<li><a href=\"https://florian.io/papers/2007_Florian_Modulated_STDP.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Reinforcement Learning through reward-modulated STDP</a></li>\n</ul>\n<h2 id=\"papers\" style=\"position:relative;\">Papers<a href=\"#papers\" aria-label=\"papers permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li><a href=\"http://catdir.loc.gov/catdir/samples/cam031/2002067657.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">2002 Gerstner Kistler</a> SPIKING NEURON MODELS: Single Neurons, Populations, Plasticity</li>\n<li><a href=\"https://0795f079-a-62cb3a1a-s-sites.googlegroups.com/site/arindambasu/writings/2010_J2.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">2010 Basu, Hasler</a> - Nullcline-Based Design of a Silicon Neuron</li>\n<li><a href=\"https://arxiv.org/pdf/1906.00851.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">2019 Thiele</a> SpikeGrad: An ANN-equivalent Computation Model for Implementing Backpropagation with Spikes</li>\n<li><a href=\"https://arxiv.org/abs/1907.13223\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">2020 Comsa et al</a> - Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function: Learning with Backpropagation <a href=\"https://arxiv.org/pdf/1907.13223.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://arxiv.org/pdf/1907.13223.pdf</a></li>\n</ul>\n<h2 id=\"my-links\" style=\"position:relative;\">My links<a href=\"#my-links\" aria-label=\"my links permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p><strong>A Minimal Spiking Neural Network</strong> to Rapidly Train and Classify Handwritten Digits in Binary and 10-Digit Tasks <a href=\"https://thesai.org/Downloads/IJARAI/Volume4No7/Paper_1-A_Minimal_Spiking_Neural_Network_to_Rapidly_Train.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">paper</a>. Guess how spikes work in this work. Pixels from black and white picture unwrapped into spike trains (facepalm)</p>\n<h2 id=\"questions\" style=\"position:relative;\">Questions<a href=\"#questions\" aria-label=\"questions permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li>How does STDP start if no synaptic connections exist a priori?</li>\n</ul>\n<h2 id=\"libraries\" style=\"position:relative;\">Libraries<a href=\"#libraries\" aria-label=\"libraries permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li><a href=\"https://brian2.readthedocs.io/en/stable/index.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Brian</a> - Brian is a simulator for spiking neural networks.</li>\n</ul>","excerpt":"Better than any words, you can get an idea how SNNs work from this animation. But here's a downside: ...in order to reach accuracy of its‚Ä¶","tableOfContents":"<ul>\n<li>\n<p><a href=\"#implementation\">Implementation</a></p>\n</li>\n<li>\n<p><a href=\"#training-methods\">Training methods</a></p>\n<ul>\n<li><a href=\"#unsupervised-learning\">Unsupervised Learning</a></li>\n<li><a href=\"#supervised-learning\">Supervised Learning</a></li>\n<li><a href=\"#reinforcement-learning\">Reinforcement Learning</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#papers\">Papers</a></p>\n</li>\n<li>\n<p><a href=\"#my-links\">My links</a></p>\n</li>\n<li>\n<p><a href=\"#questions\">Questions</a></p>\n</li>\n<li>\n<p><a href=\"#libraries\">Libraries</a></p>\n</li>\n</ul>","fields":{"socialcard":"gatsby-plugin-social-card/8c34505e-de5e-59c7-908f-14806533ec0c.jpg"},"frontmatter":{"date":null,"published":"December 20, 2022","lastModified":"December 20, 2022","title":"Spiking Neural Networks","subtitle":null,"section":"brain","draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/spiking-neural-networks.md","url":"/ai/spiking-neural-networks","next":{"excerpt":"TODO ;)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/reservoir-computing.md","frontmatter":{"title":"Reservoir Computing","date":null,"topic":true,"article":null},"id":"67d748a6-0bd6-5d7d-97f4-a8488525b883"},"previous":{"excerpt":"I am planning for some hierarchical encoding for an experiment with my rule-based system. Take MNIST data. Every picture 28x28 = 784 pixels‚Ä¶","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/spiking-mnist.md","frontmatter":{"title":"Spiking MNIST","date":"2025-05-28T00:00:00.000Z","topic":null,"article":"quest"},"id":"52d71fa8-164d-555e-883f-d0b179cdd71c"},"recentArticles":[{"excerpt":"BAM can link together data of different types. Associations...  From one side the model requires to use bipolar patterns - arrays of -1 and‚Ä¶","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/bidirectional-associative-memories.md","frontmatter":{"title":"Bidirectional Associative Memories","date":null,"topic":true,"article":null},"id":"3ae9ac87-4c8b-5f18-8f19-ee1091111f95"},{"excerpt":"Phenotypic variation of transcriptomic cell types in mouse motor cortex (paper). Scientist got neurons from different layers and regions and‚Ä¶","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/brain-map.md","frontmatter":{"title":"Brain map","date":null,"topic":true,"article":null},"id":"f4152a9b-6747-5178-aea3-0de2e3f70b04"},{"excerpt":"Neural networks with biologically plausible accounts of neurogenesis they start with a minimal topology (just input and output unit) and‚Ä¶","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cascade-correlation-neural-networks.md","frontmatter":{"title":"Cascade Correlation Neural Networks","date":null,"topic":true,"article":null},"id":"1ba88be8-cdba-50c0-a9ba-c4a082ef60e7"},{"excerpt":"ACT-R CLARION LIDA Soar (code)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cognitive-architecture.md","frontmatter":{"title":"Cognitive Architecture","date":null,"topic":true,"article":null},"id":"1acc6cfc-d238-53b6-aeed-1207dd3b1d89"},{"excerpt":"Main paper PDF stacking lstms https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms intro to‚Ä¶","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/long-short-term-memory.md","frontmatter":{"title":"Long Short-Term Memory","date":null,"topic":true,"article":null},"id":"a677bfb4-f49d-559c-8957-86db6eb41bda"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}