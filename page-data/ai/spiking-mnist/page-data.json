{"componentChunkName":"component---src-templates-blog-template-js","path":"/ai/spiking-mnist","result":{"data":{"markdownRemark":{"html":"<p>I am planning for some hierarchical encoding for an experiment with my <a href=\"/blog/regulus\">rule-based system</a>.</p>\n<p>Take MNIST data. Every picture 28x28 = 784 pixels + label. We will create 5x5 patches with no overlap. Then combine all of them into one dataset, classify, and replace 5x5 patches with class identifiers.</p>\n<p>This will give 6x6 grid on the next level (30 / 5 = 6, where 30 pixels come from 28 with one extra pixel added to all sides)</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">x x x x x x\nx x x x x x\nx x x x x x\nx x x x x x\nx x x x x x\nx x x x x x</code></pre></div>\n<p>This is the second layer with 6x6 nodes, taking possibly 10 or more values (denote this value as <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>)</p>\n<p>So for <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span> different observations (meaning, definitely not similar, not converging to one of <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span> classes) we should have different nodes active. But what if the same node is activated by different patches?</p>\n<p>9 copies of each node.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">x x\nx x -> Dx</code></pre></div>\n<p>third layer: 10 nodes x 9 copies, like 10 tiny mini layers for every node type that makes a 3x3 grid</p>\n<p>layer 1</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">D1 D1 D1\nD1 D1 D1\nD1 D1 D1</code></pre></div>\n<p>layer 2</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">D2 D2 D2\nD2 D2 D2\nD2 D2 D2</code></pre></div>\n<p>and so on</p>\n<h2 id=\"trying-brian-library\" style=\"position:relative;\">Trying brian library<a href=\"#trying-brian-library\" aria-label=\"trying brian library permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>Brian <a href=\"https://brian2.readthedocs.io/en/stable/user/equations.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">docs</a></p>\n<ul>\n<li>NeuronGroup + Synapses <a href=\"https://brian2.readthedocs.io/en/stable/examples/frompapers.Graupner_Brunel_2012.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">example</a></li>\n<li><a href=\"https://brian2.readthedocs.io/en/stable/examples/frompapers.Diehl_Cook_2015.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">STDP and MNIST</a> (somewhat different code in <a href=\"https://github.com/peter-u-diehl/stdp-mnist/blob/master/Diehl%26Cook_spiking_MNIST.py\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">their repo</a>) - but this is not an autoencoder architecture</li>\n</ul>\n<p>C++ options for SNN simulation</p>\n<ul>\n<li><a href=\"https://github.com/UCI-CARL/CARLsim5/blob/master/carlsim/kernel/src/snn_manager.cpp\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">CARLsim</a></li>\n<li></li>\n</ul>\n<h2 id=\"how-numbers-and-quantities-are-represented-in-neural-ensembles\" style=\"position:relative;\">How numbers and quantities are represented in neural ensembles?<a href=\"#how-numbers-and-quantities-are-represented-in-neural-ensembles\" aria-label=\"how numbers and quantities are represented in neural ensembles permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p><em>Numerosity estimation</em> refers to the ability to perceive and estimate quantities without explicit counting (<a href=\"https://homepages.uni-tuebingen.de/andreas.nieder/Nieder%20(2025b)%20CerCort.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">from</a> \"Numerosity coding in the brain: from early visual processing to abstract representations\" by Andreas Nieder)</p>\n<p>So some neurons have tuned responses to specific numerical ranges, possibly overlapping. Individual neurons fire maximally for their numerosity but also, with decreasing intensity, respond to nearby values. This system represents numerical magnitude in an analog, approximate manner following <a href=\"https://en.wikipedia.org/wiki/Weber%E2%80%93Fechner_law\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Weber's law</a> - discrimination becomes harder as numbers get larger. The neural representation appears to be logarithmically compressed.</p>\n<p>There's a debate if distinct neural pathways for exact symbolic numbers (like \"7\") and approximate quantities (like a collection of dots) may work the same way to represent numerosities.</p>\n<p>The intraparietal sulcus (IPS), particularly the horizontal segment, shows robust activation for numerical processing.</p>\n<p>It is known that <a href=\"https://www.philippstreicher.com/blog/neural-oscillations\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">neuronal oscillations</a> in various frequency bands may carry functionally distinct information. So, can different frequency bands encode different aspects of numerical information?</p>","excerpt":"I am planning for some hierarchical encoding for an experiment with my rule-based system. Take MNIST data. Every picture 28x28 = 784 pixels…","tableOfContents":"<ul>\n<li><a href=\"#trying-brian-library\">Trying brian library</a></li>\n<li><a href=\"#how-numbers-and-quantities-are-represented-in-neural-ensembles\">How numbers and quantities are represented in neural ensembles?</a></li>\n</ul>","fields":{"socialcard":"gatsby-plugin-social-card/52d71fa8-164d-555e-883f-d0b179cdd71c.jpg"},"frontmatter":{"date":"May 28, 2025","published":"May 28, 2025","lastModified":"May 28, 2025","title":"Spiking MNIST","subtitle":null,"section":null,"draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/spiking-mnist.md","url":"/ai/spiking-mnist","next":{"excerpt":"Better than any words, you can get an idea how SNNs work from this animation. But here's a downside: ...in order to reach accuracy of its…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/spiking-neural-networks.md","frontmatter":{"title":"Spiking Neural Networks","date":null,"topic":true,"article":null},"id":"8c34505e-de5e-59c7-908f-14806533ec0c"},"previous":{"excerpt":"I need to mix a new neural network architecture for image recognition. If we consider a simple input images, 8x8 pixels in size, where one…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/spiking-autoencoder-with-embodied-actions.md","frontmatter":{"title":"Spiking autoencoder with embodied actions","date":"2025-05-14T00:00:00.000Z","topic":null,"article":"main"},"id":"382b4b0d-346b-5e0e-b45a-ecb61bd16e92"},"recentArticles":[{"excerpt":"BAM can link together data of different types. Associations...  From one side the model requires to use bipolar patterns - arrays of -1 and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/bidirectional-associative-memories.md","frontmatter":{"title":"Bidirectional Associative Memories","date":null,"topic":true,"article":null},"id":"3ae9ac87-4c8b-5f18-8f19-ee1091111f95"},{"excerpt":"Phenotypic variation of transcriptomic cell types in mouse motor cortex (paper). Scientist got neurons from different layers and regions and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/brain-map.md","frontmatter":{"title":"Brain map","date":null,"topic":true,"article":null},"id":"f4152a9b-6747-5178-aea3-0de2e3f70b04"},{"excerpt":"Neural networks with biologically plausible accounts of neurogenesis they start with a minimal topology (just input and output unit) and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cascade-correlation-neural-networks.md","frontmatter":{"title":"Cascade Correlation Neural Networks","date":null,"topic":true,"article":null},"id":"1ba88be8-cdba-50c0-a9ba-c4a082ef60e7"},{"excerpt":"ACT-R CLARION LIDA Soar (code)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cognitive-architecture.md","frontmatter":{"title":"Cognitive Architecture","date":null,"topic":true,"article":null},"id":"1acc6cfc-d238-53b6-aeed-1207dd3b1d89"},{"excerpt":"Main paper PDF stacking lstms https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms intro to…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/long-short-term-memory.md","frontmatter":{"title":"Long Short-Term Memory","date":null,"topic":true,"article":null},"id":"a677bfb4-f49d-559c-8957-86db6eb41bda"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}