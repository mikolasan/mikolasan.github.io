{"componentChunkName":"component---src-templates-blog-template-js","path":"/ai/diffusion-models","result":{"data":{"markdownRemark":{"html":"<p><strong>Also</strong>: <a href=\"/ai/stable-diffusion-generates-3d-content\">Stable Diffusion and 3D</a></p>\n<h2 id=\"tutorials\" style=\"position:relative;\">Tutorials<a href=\"#tutorials\" aria-label=\"tutorials permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li><a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a></li>\n<li>Another diffusion tutorial <a href=\"https://github.com/Project-MONAI/GenerativeModels/blob/main/tutorials/generative/2d_ddpm/2d_ddpm_compare_schedulers.ipynb\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://github.com/Project-MONAI/GenerativeModels/blob/main/tutorials/generative/2d_ddpm/2d_ddpm_compare_schedulers.ipynb</a></li>\n<li>PyTorch code with explanation <a href=\"https://huggingface.co/blog/annotated-diffusion\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">link</a></li>\n<li>no gaussian noise, <a href=\"https://muse-model.github.io/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">masks instead</a>. any other distortion is good also <a href=\"https://arxiv.org/pdf/2208.09392.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://arxiv.org/pdf/2208.09392.pdf</a></li>\n</ul>\n<h2 id=\"papers\" style=\"position:relative;\">Papers<a href=\"#papers\" aria-label=\"papers permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li>diffusion probabilistic models (<a href=\"https://arxiv.org/abs/1503.03585\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Sohl-Dickstein et al., 2015</a>)</li>\n<li>noise-conditioned score network (<a href=\"https://arxiv.org/abs/1907.05600\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">NCSN; Yang &#x26; Ermon, 2019</a>)</li>\n<li>denoising diffusion probabilistic models (<a href=\"https://arxiv.org/abs/2006.11239\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">DDPM; Ho et al. 2020</a>, <a href=\"https://github.com/lucidrains/denoising-diffusion-pytorch\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">example</a>, <a href=\"https://github.com/yiyixuxu/denoising-diffusion-flax\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">tricks</a>)</li>\n</ul>\n<blockquote>\n<p>Our neural network architecture follows the backbone of PixelCNN++, which is a U-Net based on a Wide ResNet</p>\n<p><em>Denoising Diffusion Probabilistic Models</em></p>\n</blockquote>\n<ul>\n<li>adding more confusing physics: <a href=\"https://arxiv.org/pdf/2006.09011.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Annealed Langevin dynamics</a></li>\n<li><a href=\"https://arxiv.org/pdf/2208.04202.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">self-conditioning</a></li>\n<li><a href=\"https://arxiv.org/pdf/2204.00227.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">P2 weighting</a> (<a href=\"https://github.com/jychoi118/P2-weighting\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">PyTorch code</a>)</li>\n<li><a href=\"https://openreview.net/pdf?id=-NEXDKk8gZ\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">non linear scheduling</a></li>\n<li>from OpenAI <a href=\"https://arxiv.org/pdf/2105.05233.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">bragging that diffusion beats GAN</a></li>\n<li>some people referring that UNet model in duffision is taken from <a href=\"https://github.com/openai/pixel-cnn\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">PixelCNN++</a></li>\n</ul>\n<blockquote>\n<p>condition on whole pixels, rather than R/G/B sub-pixels</p>\n<p><em>PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications</em></p>\n</blockquote>\n<h2 id=\"dataset-poses\" style=\"position:relative;\">Dataset: poses<a href=\"#dataset-poses\" aria-label=\"dataset poses permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>I incline to small but coherent datasets. This will make every diffusion model precise in their little purposes. Which means I need to work on my dataset. It has already some categories and I will start to train on &#x3C;redacted> <a href=\"/ai/unsupervised-image-classification-with-gan\">recognition models using GAN</a>, but to generate something interesting I need to recognize poses and generate new ones (I saw GAN models can do it).</p>\n<p>Pose recognition is very helpful for robots anyway. That’s how they can learn new movements, though their bone and “muscle” structure is different. But maybe they can imitate to some degree.</p>\n<h2 id=\"extra\" style=\"position:relative;\">Extra<a href=\"#extra\" aria-label=\"extra permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>It's possible to get access to TPU v3-8 (similar to 8 V100 GPUs) with <a href=\"https://sites.research.google/trc/about/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Google TRC program</a>.</p>\n<p>On top you need the Super resolution models. From <a href=\"https://github.com/deep-floyd/IF\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">IF</a>, for example.\nAnd <a href=\"https://huggingface.co/blog/if\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">tutorial</a> to use small memory footprint.</p>\n<h2 id=\"lessons\" style=\"position:relative;\">Lessons<a href=\"#lessons\" aria-label=\"lessons permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p><strong>Diffusion model staggers and not improving loss</strong></p>\n<p>It’s normal. Diffusion models can plateau at 0.1 or somewhere there. It’s better not fixate on that</p>\n<p><strong>Why batch size not reducing train time?</strong></p>\n<p>From <a href=\"https://twitter.com/Yampeleg/status/1674034884652802048\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">this tweet</a> TL;DR:</p>\n<ul>\n<li>Maximum speed: Largest batch_size as possible.</li>\n<li>Maximum generalization: small batch_size, and increase throughout the training.</li>\n</ul>\n<p>There is a lot of confusion about neural networks batch size during training, here is what I know. The <code class=\"language-text\">batch_size</code> is a balance between the training speed and generalization performance.\nGenerally, up to a certain limit (can be around around 8-9 samples), the smaller the batch: the better the generalization performance on the validation set.\nIn addition: Increasing the <code class=\"language-text\">batch_size</code> throughout the training also helps with the validation performance.</p>\n<p>If you changed your <code class=\"language-text\">batch_size</code>, it is important to also change the <code class=\"language-text\">learning_rate</code> as well. A good ratio for this is according to the ratio of the <code class=\"language-text\">batch_size</code> change. Larger batches: Need larger <code class=\"language-text\">learning_rate</code>. Smaller batches Need smaller <code class=\"language-text\">learning_rate</code>.</p>\n<h2 id=\"3d\" style=\"position:relative;\">3D<a href=\"#3d\" aria-label=\"3d permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li><a href=\"https://fantasia3d.github.io/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Fantasia3D</a></li>\n<li><a href=\"https://github.com/ashawkey/stable-dreamfusion\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Dreamfusion</a> (<a href=\"https://colab.research.google.com/drive/1MXT3yfOFvO0ooKEfiUUvTKwUkrrlCHpF?usp=sharing#scrollTo=VklXFNisIrDo\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">colab</a>)</li>\n</ul>","excerpt":"Also: Stable Diffusion and 3D Tutorials https://lilianweng.github.io/posts/2021-07-11-diffusion-models/ Another diffusion tutorial https…","tableOfContents":"<ul>\n<li><a href=\"#tutorials\">Tutorials</a></li>\n<li><a href=\"#papers\">Papers</a></li>\n<li><a href=\"#dataset-poses\">Dataset: poses</a></li>\n<li><a href=\"#extra\">Extra</a></li>\n<li><a href=\"#lessons\">Lessons</a></li>\n<li><a href=\"#3d\">3D</a></li>\n</ul>","fields":{"socialcard":"gatsby-plugin-social-card/f5fdb83b-084d-5996-b6c6-a012d6327328.jpg"},"frontmatter":{"date":"May 27, 2023","published":"May 27, 2023","lastModified":"May 27, 2023","title":"Diffusion models","subtitle":null,"section":null,"draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/diffusion-models.md","url":"/ai/diffusion-models","next":{"excerpt":"Questions Are embeddings required for any type of data? Why sin/cos? What stacks add to the whole picture? How are they different? Why…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/the-smallest-transformer.md","frontmatter":{"title":"The smallest Transformer","date":"2023-06-03T00:00:00.000Z","topic":null,"article":"quest"},"id":"bf0eddd7-c885-5815-8d65-8ba8c9bf0651"},"previous":{"excerpt":"Papers Circular CNN kernels https://arxiv.org/abs/2107.02451 Help with image rotation https://www.mdpi.com/2072-4292/10/6/934 Questions How…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/not-square-gan.md","frontmatter":{"title":"Not square GAN","date":"2023-05-26T00:00:00.000Z","topic":null,"article":"quest"},"id":"66410355-6bd5-5fc4-a9c3-582a804cbcaf"},"recentArticles":[{"excerpt":"BAM can link together data of different types. Associations...  From one side the model requires to use bipolar patterns - arrays of -1 and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/bidirectional-associative-memories.md","frontmatter":{"title":"Bidirectional Associative Memories","date":null,"topic":true,"article":null},"id":"3ae9ac87-4c8b-5f18-8f19-ee1091111f95"},{"excerpt":"Phenotypic variation of transcriptomic cell types in mouse motor cortex (paper). Scientist got neurons from different layers and regions and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/brain-map.md","frontmatter":{"title":"Brain map","date":null,"topic":true,"article":null},"id":"f4152a9b-6747-5178-aea3-0de2e3f70b04"},{"excerpt":"Neural networks with biologically plausible accounts of neurogenesis they start with a minimal topology (just input and output unit) and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cascade-correlation-neural-networks.md","frontmatter":{"title":"Cascade Correlation Neural Networks","date":null,"topic":true,"article":null},"id":"1ba88be8-cdba-50c0-a9ba-c4a082ef60e7"},{"excerpt":"ACT-R CLARION LIDA Soar (code)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cognitive-architecture.md","frontmatter":{"title":"Cognitive Architecture","date":null,"topic":true,"article":null},"id":"1acc6cfc-d238-53b6-aeed-1207dd3b1d89"},{"excerpt":"Main paper PDF stacking lstms https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms intro to…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/long-short-term-memory.md","frontmatter":{"title":"Long Short-Term Memory","date":null,"topic":true,"article":null},"id":"a677bfb4-f49d-559c-8957-86db6eb41bda"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}