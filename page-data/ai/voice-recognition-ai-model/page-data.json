{"componentChunkName":"component---src-templates-blog-template-js","path":"/ai/voice-recognition-ai-model","result":{"data":{"markdownRemark":{"html":"<p>First thing you may find is <a href=\"https://github.com/openai/whisper\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Whisper</a> by OpenAI. Surprisingly it's open sourced, but the normal model requires 10GB of video memory which is indimidating for an average laptop (my laptop is from 2018). But what can be better than Python? That's right C++ rewrite <a href=\"https://github.com/ggerganov/whisper.cpp\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Whisper.cpp</a>. Another optimization is <a href=\"https://github.com/guillaumekln/faster-whisper\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">faster-whisper</a>.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/ggerganov/whisper.cpp.git\n<span class=\"token builtin class-name\">cd</span> whisper.cpp\nmodels<span class=\"token punctuation\">\\</span>download-ggml-model.cmd medium\n\ncmake <span class=\"token parameter variable\">-DCMAKE_BUILD_TYPE</span><span class=\"token operator\">=</span>Release <span class=\"token parameter variable\">-S</span> <span class=\"token builtin class-name\">.</span> <span class=\"token parameter variable\">-B</span> build\ncmake <span class=\"token parameter variable\">--build</span> build <span class=\"token parameter variable\">--target</span> all</code></pre></div>\n<p>Install <strong>ffmpeg</strong> from <a href=\"https://www.gyan.dev/ffmpeg/builds/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">here</a> for example. I have this folder in <code class=\"language-text\">PATH</code> for my user account <code class=\"language-text\">C:\\Users\\neupo\\.local\\bin</code>, so I extract <code class=\"language-text\">ffmpeg.exe</code> there.</p>\n<p>Then convert audio files from Voice Recorder from <code class=\"language-text\">m4a</code> to <code class=\"language-text\">wav</code></p>\n<p>I use <strong>Git Bash</strong> in order to use a bash script (any other MSYS2 install will work too).</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">pushd</span> /c/Users/neupo/Documents/Personal/VoiceRecordings\n<span class=\"token function\">ls</span> <span class=\"token parameter variable\">-1</span> *.m4a <span class=\"token operator\">|</span> <span class=\"token keyword\">while</span> <span class=\"token builtin class-name\">read</span> <span class=\"token parameter variable\">-r</span> input_file\n<span class=\"token keyword\">do</span>\n  <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"'<span class=\"token variable\">$input_file</span>' -> '<span class=\"token variable\">${input_file<span class=\"token operator\">%</span>.m4a}</span>.wav'\"</span>\n  <span class=\"token assign-left variable\">output_file</span><span class=\"token operator\">=</span><span class=\"token string\">\"<span class=\"token variable\">${input_file<span class=\"token operator\">%</span>.m4a}</span>.wav\"</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">[</span> <span class=\"token operator\">!</span> <span class=\"token parameter variable\">-f</span> <span class=\"token string\">\"<span class=\"token variable\">$output_file</span>\"</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span> <span class=\"token keyword\">then</span>\n    ffmpeg <span class=\"token parameter variable\">-hide_banner</span> <span class=\"token parameter variable\">-loglevel</span> error <span class=\"token parameter variable\">-nostats</span> <span class=\"token parameter variable\">-i</span> <span class=\"token string\">\"<span class=\"token variable\">$input_file</span>\"</span> <span class=\"token parameter variable\">-ar</span> <span class=\"token number\">16000</span> <span class=\"token parameter variable\">-ac</span> <span class=\"token number\">1</span> <span class=\"token parameter variable\">-c:a</span> pcm_s16le <span class=\"token string\">\"<span class=\"token variable\">$output_file</span>\"</span> \n  <span class=\"token keyword\">fi</span>\n<span class=\"token keyword\">done</span>\n<span class=\"token function\">popd</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">main.exe -m c:\\Users\\neupo\\robot\\whisper.cpp\\models\\ggml-medium.bin -f \"c:\\Users\\neupo\\robot\\whisper.cpp\\samples\\New Recording 8.wav\"</code></pre></div>\n<h3 id=\"output\" style=\"position:relative;\">Output<a href=\"#output\" aria-label=\"output permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">c:\\Users\\neupo\\robot\\whisper.cpp>main.exe -m c:\\Users\\neupo\\robot\\whisper.cpp\\models\\ggml-medium.bin -f \"c:\\Users\\neupo\\robot\\whispe\nr.cpp\\samples\\New Recording 8.wav\"\nwhisper_init_from_file_no_state: loading model from 'c:\\Users\\neupo\\robot\\whisper.cpp\\models\\ggml-medium.bin'\nwhisper_model_load: loading model\nwhisper_model_load: n_vocab       = 51865\nwhisper_model_load: n_audio_ctx   = 1500\nwhisper_model_load: n_audio_state = 1024\nwhisper_model_load: n_audio_head  = 16\nwhisper_model_load: n_audio_layer = 24\nwhisper_model_load: n_text_ctx    = 448\nwhisper_model_load: n_text_state  = 1024\nwhisper_model_load: n_text_head   = 16\nwhisper_model_load: n_text_layer  = 24\nwhisper_model_load: n_mels        = 80\nwhisper_model_load: ftype         = 1\nwhisper_model_load: qntvr         = 0\nwhisper_model_load: type          = 4\nwhisper_model_load: mem required  = 1899.00 MB (+   43.00 MB per decoder)\nwhisper_model_load: adding 1608 extra tokens\nwhisper_model_load: model ctx     = 1462.58 MB\nwhisper_model_load: model size    = 1462.12 MB\nwhisper_init_state: kv self size  =   42.00 MB\nwhisper_init_state: kv cross size =  140.62 MB\n\nsystem_info: n_threads = 4 / 8 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_\nSIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | COREML = 0 |\n\nmain: processing 'c:\\Users\\neupo\\robot\\whisper.cpp\\samples\\New Recording 8.wav' (4921121 samples, 307.6 sec), 4 threads, 1 processor\ns, lang = en, task = transcribe, timestamps = 1 ...\n\n\n[00:00:00.000 --> 00:00:13.920]   Hello, I'm going to the North Peak and maybe Bridge Mountain.\n[00:00:13.920 --> 00:00:16.520]   I think it's a trail.\n[00:00:16.520 --> 00:00:18.920]   Trail name.\n[00:00:18.920 --> 00:00:19.920]   Bridge Mountain.\n[00:00:19.920 --> 00:00:31.040]   So, while I'm going there I'm thinking about...\n[00:00:31.040 --> 00:00:35.880]   If you name it really...\n[00:00:35.880 --> 00:00:38.720]   Walk and road is all about artificial intelligence.\n[00:00:38.720 --> 00:00:54.720]   I want to critique, approach and excitement of some researchers who review or they view...\n[00:00:54.720 --> 00:01:02.640]   No, they see large language models as GPT.\n[00:01:02.640 --> 00:01:15.560]   It's our first step to...\n[00:01:15.560 --> 00:01:19.960]   To better models of intelligence that we have.\n[00:01:19.960 --> 00:01:26.120]   Like algorithms that are smart in some way.\n[00:01:26.120 --> 00:01:29.400]   You can call them like smart algorithms, right?\n[00:01:29.400 --> 00:01:37.320]   No one uses that term, but what it means is that you don't need to program it.\n[00:01:37.320 --> 00:01:55.080]   You maybe locally specify what it should do and it finds its way how better do it in some\n[00:01:55.080 --> 00:02:02.400]   optimal way.\n[00:02:02.400 --> 00:02:10.640]   And of course, maybe it's not really complex algorithms, like not algorithms, complex tasks.\n[00:02:10.640 --> 00:02:13.440]   Like find all...\n[00:02:13.440 --> 00:02:16.400]   Find the formula for any prime number.\n[00:02:16.400 --> 00:02:22.280]   Say this and it's like \"oh\" and it starts crunching all theorems.\n[00:02:22.280 --> 00:02:34.200]   Or like reinventing in few hours what humanity developed in centuries, let's say, right?\n[00:02:34.200 --> 00:02:36.480]   That's maybe some people would expect.\n[00:02:36.480 --> 00:02:44.640]   But what we already see and what many people are really excited about, actually scared about,\n[00:02:44.640 --> 00:02:52.280]   is some mundane, some boring but time-consuming tasks.\n[00:02:52.280 --> 00:03:01.840]   I don't know, like writing emails, summarizing big text in some short summary.\n[00:03:01.840 --> 00:03:09.800]   You don't need to maybe read a whole book or big article, some complex article, if you're\n[00:03:09.800 --> 00:03:15.600]   looking for some specific, I guess, moment.\n[00:03:15.600 --> 00:03:23.920]   It's like you want to understand if that article contains that, which can just ask that algorithm\n[00:03:23.920 --> 00:03:27.600]   this question and it will do it in a second, right?\n[00:03:27.600 --> 00:03:31.520]   It will just immediately answer you.\n[00:03:31.520 --> 00:03:33.920]   The problem is do we trust that answer?\n[00:03:33.920 --> 00:03:40.800]   Or is the problem that the output not always is true based on data?\n[00:03:40.800 --> 00:03:44.040]   It can... because it needs to answer something.\n[00:03:44.040 --> 00:03:48.760]   This is the problem that I assume will be solved soon.\n[00:03:48.760 --> 00:03:52.760]   That should be something simple.\n[00:03:52.760 --> 00:04:06.960]   Because if this is a model based on probabilities, then for the correct answer we have high probab\nility.\n[00:04:06.960 --> 00:04:12.080]   Or maybe the common myth, so we have a high probability there.\n[00:04:12.080 --> 00:04:20.920]   If you put some strange, unbelievable conditions, it will answer anyway.\n[00:04:20.920 --> 00:04:27.400]   But what if... can it ask other questions, additional questions?\n[00:04:27.400 --> 00:04:29.480]   Can it say that doesn't make sense?\n[00:04:29.480 --> 00:04:36.000]   For some reason they didn't put such guards there, so it just always answers.\n[00:04:36.000 --> 00:04:47.080]   I mean, they put some guards, but it can say \"SNI model, I cannot say about this and this,\n[00:04:47.080 --> 00:04:52.400]   so I don't have enough knowledge about it\".\n[00:04:52.400 --> 00:05:00.480]   Or if it's really low probability, like I said, once it responds \"bro\", and says \"what\n[00:05:00.480 --> 00:05:01.480]   do you mean?\"\n[00:05:01.480 --> 00:05:03.640]   And I don't understand, give me no context.\n[00:05:03.640 --> 00:05:06.480]   (heavy breathing)\n[00:05:06.480 --> 00:05:29.960]   Thanks for watching.\n\n\nwhisper_print_timings:     load time =  1334.92 ms\nwhisper_print_timings:     fallbacks =   0 p /   0 h\nwhisper_print_timings:      mel time =  5091.06 ms\nwhisper_print_timings:   sample time =  3030.49 ms /   721 runs (    4.20 ms per run)\nwhisper_print_timings:   encode time = 439502.44 ms /    15 runs (29300.16 ms per run)\nwhisper_print_timings:   decode time = 83150.84 ms /   719 runs (  115.65 ms per run)\nwhisper_print_timings:    total time = 532588.44 ms</code></pre></div>\n<h2 id=\"cuda-optimized-version\" style=\"position:relative;\">CUDA optimized version<a href=\"#cuda-optimized-version\" aria-label=\"cuda optimized version permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">-- Building for: Visual Studio 17 2022\n-- Selecting Windows SDK version 10.0.20348.0 to target Windows 10.0.19045.\n-- The C compiler identification is MSVC 19.32.31332.0\n-- The CXX compiler identification is MSVC 19.32.31332.0\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.32.31326/bin/Hostx64/x64/c\nl.exe - skipped\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Check for working CXX compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.32.31326/bin/Hostx64/x64\n/cl.exe - skipped\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Found Git: C:/Program Files/Git/cmd/git.exe (found version \"2.28.0.rc2.windows.1\")\n-- Looking for pthread.h\n-- Looking for pthread.h - not found\n-- Found Threads: TRUE\n-- Found CUDAToolkit: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3/include (found version \"11.3.109\")\n-- cuBLAS found\nCMake Error at C:/Program Files/CMake/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:470 (message):\n  No CUDA toolset found.\nCall Stack (most recent call first):\n  C:/Program Files/CMake/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:6 (CMAKE_DETERMINE_COMPILER_ID_BUILD)\n  C:/Program Files/CMake/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake:59 (__determine_compiler_id_test)\n  C:/Program Files/CMake/share/cmake-3.22/Modules/CMakeDetermineCUDACompiler.cmake:298 (CMAKE_DETERMINE_COMPILER_ID)\n  CMakeLists.txt:151 (enable_language)\n\n\n-- Configuring incomplete, errors occurred!\nSee also \"C:/Users/neupo/robot/whisper.cpp/build/CMakeFiles/CMakeOutput.log\".\nSee also \"C:/Users/neupo/robot/whisper.cpp/build/CMakeFiles/CMakeError.log\".\n\nc:\\Users\\neupo\\robot\\whisper.cpp>nvcc --help\n\nUsage  : nvcc [options] &lt;inputfile></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">cmake -G \"Visual Studio 17 2022\" -T version=19.32,cuda=11.3,host=x64,VCTargetsPath=\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\ext\nras\\visual_studio_integration\\MSBuildExtensions\" -DCMAKE_BUILD_TYPE=Release -DWHISPER_CUBLAS=ON -S . -B build</code></pre></div>\n<p>copy files from <code class=\"language-text\">C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.3\\extras\\visual_studio_integration\\MSBuildExtensions</code> to <code class=\"language-text\">C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\Msbuild\\Microsoft\\VC\\v170\\BuildCustomizations</code></p>\n<p><a href=\"https://stackoverflow.com/questions/56636714/cuda-compile-problems-on-windows-cmake-error-no-cuda-toolset-found\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://stackoverflow.com/questions/56636714/cuda-compile-problems-on-windows-cmake-error-no-cuda-toolset-found</a></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">cmake -G \"Visual Studio 17 2022\" -A x64 -DCMAKE_BUILD_TYPE=Release -DWHISPER_CUBLAS=ON -S . -B build\ndevenv build\\whisper.cpp.sln /build</code></pre></div>\n<h2 id=\"other-versions-of-whisper\" style=\"position:relative;\">Other versions of Whisper<a href=\"#other-versions-of-whisper\" aria-label=\"other versions of whisper permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li><a href=\"https://github.com/shirayu/whispering\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">whisper for streaming</a></li>\n<li><a href=\"https://github.com/ggerganov/whisper.cpp/tree/master\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">whisper C++</a></li>\n<li><a href=\"https://github.com/guillaumekln/faster-whisper\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">faster whisper</a></li>\n<li><a href=\"https://github.com/saharmor/whisper-playground\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">whisper playground</a></li>\n</ul>\n<h2 id=\"next-gen\" style=\"position:relative;\">Next gen<a href=\"#next-gen\" aria-label=\"next gen permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>I looked into voice recognition models and noticed that they might be not very fast. And when I watched any demonstration of dog robots or other assistants I noticed that when they obtain commands through natural language processing then it’s very noticeable how long it takes for them to process and come out with the response. The pipeline is something like: record a buffer of audio, send to the server, save it on intermediate server in text format, analyze the sentence, wait if it’s not complete, verify if the sentence makes sense by trying to answer it and checking if the answer has a good confidence level or also pass it through moderation or alignment filter, then send this text to another model that can synthesize audio from it, send finally receive audio back on the edge device and play it through speakers. And hope that all these audio streams are sent via a good wifi signal and not GPRS or some other exotic radio format.</p>\n<p>But you already know, from experience, that the answer is ready usually before an interlocutor finishes the sentence. Even if it’s “I don’t know” reply. Another nuance is context. If you didn’t follow the conversation and join it only for the last sentence then you will be lost if it is going to be your turn.</p>\n<p>The brain is an inference machine. It starts digging in the context from the beginning and it starts predicting in two directions. First, what the interlocutor is going to say next? It helps to recognize speech and aligns our context and makes adjustments if needed. Second, is to construct our relations and comments to the topic based on associations and knowledge that are retrieved from memory.</p>\n<p>Then how it should work for making quick responses. No audio-to-text-to-meaning conversion. Skip the text part. There’s an article that says that language is not important for thinking and making decisions. Yes, thoughts work without sound or text. And they work similarly for different languages.</p>","excerpt":"First thing you may find is Whisper by OpenAI. Surprisingly it's open sourced, but the normal model requires 10GB of video memory which is…","tableOfContents":"<ul>\n<li>\n<ul>\n<li><a href=\"#output\">Output</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#cuda-optimized-version\">CUDA optimized version</a></p>\n</li>\n<li>\n<p><a href=\"#other-versions-of-whisper\">Other versions of Whisper</a></p>\n</li>\n<li>\n<p><a href=\"#next-gen\">Next gen</a></p>\n</li>\n</ul>","fields":{"socialcard":"gatsby-plugin-social-card/5f4c1325-32e2-5290-b478-74980b5d1c78.jpg"},"frontmatter":{"date":"May 18, 2023","published":"May 18, 2023","lastModified":"May 18, 2023","title":"Voice recognition AI model","subtitle":null,"section":null,"draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/voice-recognition-ai-model.md","url":"/ai/voice-recognition-ai-model","next":{"excerpt":"Papers Circular CNN kernels https://arxiv.org/abs/2107.02451 Help with image rotation https://www.mdpi.com/2072-4292/10/6/934 Questions How…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/not-square-gan.md","frontmatter":{"title":"Not square GAN","date":"2023-05-26T00:00:00.000Z","topic":null,"article":"quest"},"id":"66410355-6bd5-5fc4-a9c3-582a804cbcaf"},"previous":{"excerpt":"A long time ago, I was thinking about systems that perceive only video input. But the more I read about image processing, the more I get a…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/convolutional-neural-networks.md","frontmatter":{"title":"Convolutional Neural Networks","date":"2023-05-13T00:00:00.000Z","topic":true,"article":null},"id":"93583a77-b3f1-56e5-8bb4-f637131b3ded"},"recentArticles":[{"excerpt":"BAM can link together data of different types. Associations...  From one side the model requires to use bipolar patterns - arrays of -1 and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/bidirectional-associative-memories.md","frontmatter":{"title":"Bidirectional Associative Memories","date":null,"topic":true,"article":null},"id":"3ae9ac87-4c8b-5f18-8f19-ee1091111f95"},{"excerpt":"Phenotypic variation of transcriptomic cell types in mouse motor cortex (paper). Scientist got neurons from different layers and regions and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/brain-map.md","frontmatter":{"title":"Brain map","date":null,"topic":true,"article":null},"id":"f4152a9b-6747-5178-aea3-0de2e3f70b04"},{"excerpt":"Neural networks with biologically plausible accounts of neurogenesis they start with a minimal topology (just input and output unit) and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cascade-correlation-neural-networks.md","frontmatter":{"title":"Cascade Correlation Neural Networks","date":null,"topic":true,"article":null},"id":"1ba88be8-cdba-50c0-a9ba-c4a082ef60e7"},{"excerpt":"ACT-R CLARION LIDA Soar (code)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cognitive-architecture.md","frontmatter":{"title":"Cognitive Architecture","date":null,"topic":true,"article":null},"id":"1acc6cfc-d238-53b6-aeed-1207dd3b1d89"},{"excerpt":"Main paper PDF stacking lstms https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms intro to…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/long-short-term-memory.md","frontmatter":{"title":"Long Short-Term Memory","date":null,"topic":true,"article":null},"id":"a677bfb4-f49d-559c-8957-86db6eb41bda"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}