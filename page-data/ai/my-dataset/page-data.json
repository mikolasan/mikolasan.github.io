{"componentChunkName":"component---src-templates-blog-template-js","path":"/ai/my-dataset","result":{"data":{"markdownRemark":{"html":"<h2 id=\"initial-plan\" style=\"position:relative;\">Initial plan<a href=\"#initial-plan\" aria-label=\"initial plan permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ol>\n<li>read about crop blur technique in modern datasets. (I think I’ve seen it when <a href=\"https://arxiv.org/pdf/1710.10196v3.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">I read about Celeb HQ</a>)</li>\n</ol>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; flex:2.1447368421052633;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/522aea3bb0d2dac97112d781a9efa738/71c1d/creating-celeba-hq-dataset.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 46.62576687116564%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB+0lEQVR42mP4////1YtnV6xcsW//7luXTp8/cej8sX3HD+85ffLwgd3bD+/ffeLw/n07tx7at/vciUOnj+7dtmnDxvXrnjx+CNTIAMTTG7NKPTVDnHVnVSfWRNp5GkgYaYiHBZi5aolaGCqEeBi4aok5Wmkk+hpVBOke7Er01hFeMG8qSPOff/8XdhS+XFuzuTttfkPmxGy/WfleBydnJYU5rCgL3DUxJ9bfek1NyMYJuc7m6mUBBl92929sDD95eDvU5pAA3wWJ1p0prtPK4lJ9rLSkBIt8TRQUpO3VJYoCLBXkpd315HKDbLl4+S3kBD4tLp6U7bJl8xqo5tSMLAc9FT9X+wVNedXpkTo6Oq5Wxi7Ojo4WRu525t5uTs5Wxt6ONhYWFqpKSpNTfELdzBYuXgjR/O/79+/v37//+Onzl08fv3/7+unTxw8fPgAFgfTnT5++ffv66tWrL58///jx/fPnL09evHr34dOfP3+gNj969OjmzRs3bly/du3ajRs379y5cw0MgCJAcOnSpatXrlwFA6Cy27duXbx48c2bN1DND+7fv3z58g0YALKvXwNpu3379k0YALKBhgIZd+7evXzp0pu3b6GaP3369Pbt248fPwIZH95/ePfuHVDu27dv//79Azrv79+/v3///gMCUAZQBCj1//9/AFBsbdcnSf3OAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Creating the CELEBA-HQ dataset. We start with a JPEG image (a) from the CelebA in-the-wild dataset. We improve the visual quality (b,top) through JPEG artifact removal (b,middle) and 4x super-resolution (b,bottom). We then extend the image through mirror padding (c) and Gaussian filtering (d) to produce a visually pleasing depth-of-field effect. Finally, we use the facial landmark locations to select an appropriate crop region (e) and perform high-quality resampling to obtain the final image at 1024 × 1024 resolution (f).\"\n        title=\"\"\n        src=\"/static/522aea3bb0d2dac97112d781a9efa738/a6d36/creating-celeba-hq-dataset.png\"\n        srcset=\"/static/522aea3bb0d2dac97112d781a9efa738/222b7/creating-celeba-hq-dataset.png 163w,\n/static/522aea3bb0d2dac97112d781a9efa738/ff46a/creating-celeba-hq-dataset.png 325w,\n/static/522aea3bb0d2dac97112d781a9efa738/a6d36/creating-celeba-hq-dataset.png 650w,\n/static/522aea3bb0d2dac97112d781a9efa738/e548f/creating-celeba-hq-dataset.png 975w,\n/static/522aea3bb0d2dac97112d781a9efa738/3c492/creating-celeba-hq-dataset.png 1300w,\n/static/522aea3bb0d2dac97112d781a9efa738/71c1d/creating-celeba-hq-dataset.png 1536w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<ol start=\"2\">\n<li>crop to faces: recognize faces, center, add padding if needed, blur/mirror background if needed</li>\n<li>train a diffusion model on them (what model to use, what library to use, what video card to use (nvidia/AMD)???)</li>\n</ol>\n<h2 id=\"image-files-into-dataset\" style=\"position:relative;\">Image files into dataset<a href=\"#image-files-into-dataset\" aria-label=\"image files into dataset permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>Even when you have folders with JPG on PNG images, you still need to convert them into two-dimensional arrays across 3 color channels (red, green, and blue) that will be ready for models and easy to deploy or share.</p>\n<p>So, first we start with some utilities like making a list of files</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pathlib\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_all_items</span><span class=\"token punctuation\">(</span>root<span class=\"token punctuation\">:</span> pathlib<span class=\"token punctuation\">.</span>Path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> item <span class=\"token keyword\">in</span> root<span class=\"token punctuation\">.</span>iterdir<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> item<span class=\"token punctuation\">.</span>is_file<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            ext <span class=\"token operator\">=</span> item<span class=\"token punctuation\">.</span>suffix<span class=\"token punctuation\">.</span>lower<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">if</span> ext <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'.png'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'.jpg'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">yield</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> item<span class=\"token punctuation\">.</span>is_dir<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">yield</span> <span class=\"token keyword\">from</span> get_all_items<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n\nfile_list_name <span class=\"token operator\">=</span> <span class=\"token string\">\"dataset_file_list.txt\"</span>\n<span class=\"token keyword\">with</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>file_list_name<span class=\"token punctuation\">,</span> <span class=\"token string\">\"w\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> output<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> filename <span class=\"token keyword\">in</span> get_all_items<span class=\"token punctuation\">(</span>pathlib<span class=\"token punctuation\">.</span>Path<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>filename<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n'</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This list will help us when we use the <code class=\"language-text\">datasets</code> library</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> datasets <span class=\"token keyword\">import</span> load_dataset\n\ndataset <span class=\"token operator\">=</span> load_dataset<span class=\"token punctuation\">(</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">,</span> data_files<span class=\"token operator\">=</span>file_list_name<span class=\"token punctuation\">,</span> split<span class=\"token operator\">=</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Files that I collected were of different size and aspect ratios. Neural networks (or diffusion models in particular) need small square pictures for the input. This is how we transform our dataset to 64x64</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> PIL <span class=\"token keyword\">import</span> Image\n<span class=\"token keyword\">from</span> torchvision <span class=\"token keyword\">import</span> transforms\n\nimage_size <span class=\"token operator\">=</span> <span class=\"token number\">64</span>\n\npreprocess <span class=\"token operator\">=</span> transforms<span class=\"token punctuation\">.</span>Compose<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        transforms<span class=\"token punctuation\">.</span>Resize<span class=\"token punctuation\">(</span>image_size<span class=\"token punctuation\">,</span> interpolation<span class=\"token operator\">=</span>transforms<span class=\"token punctuation\">.</span>InterpolationMode<span class=\"token punctuation\">.</span>BILINEAR<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        transforms<span class=\"token punctuation\">.</span>RandomCrop<span class=\"token punctuation\">(</span>image_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        transforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># Convert to tensor (0, 1)</span>\n        transforms<span class=\"token punctuation\">.</span>Normalize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># Map to (-1, 1)</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">transform</span><span class=\"token punctuation\">(</span>examples<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    images <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>Image<span class=\"token punctuation\">.</span><span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> e <span class=\"token keyword\">in</span> examples<span class=\"token punctuation\">[</span><span class=\"token string\">\"text\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n    proc_images <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>preprocess<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">.</span>convert<span class=\"token punctuation\">(</span><span class=\"token string\">\"RGB\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> image <span class=\"token keyword\">in</span> images<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">return</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"images\"</span><span class=\"token punctuation\">:</span> proc_images<span class=\"token punctuation\">}</span>\n\ndataset_resized <span class=\"token operator\">=</span> dataset<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>transform<span class=\"token punctuation\">,</span> batched<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>It's time to save the results. We will use <strong>parquet</strong> - a binary, more compact format.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># https://huggingface.co/docs/datasets/v2.14.0/en/process#save</span>\n<span class=\"token comment\"># dataset_resized.save_to_disk(\"dataset/dataset-resized-64\")</span>\n\ndataset_resized<span class=\"token punctuation\">.</span>to_parquet<span class=\"token punctuation\">(</span><span class=\"token string\">\"dataset-resized-64.parquet\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"using-dataset-examples\" style=\"position:relative;\">Using dataset examples<a href=\"#using-dataset-examples\" aria-label=\"using dataset examples permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<h3 id=\"load-and-show-images\" style=\"position:relative;\">Load and show images<a href=\"#load-and-show-images\" aria-label=\"load and show images permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> torchvision\n<span class=\"token keyword\">from</span> datasets <span class=\"token keyword\">import</span> load_dataset\n<span class=\"token keyword\">from</span> PIL <span class=\"token keyword\">import</span> Image\n\ndataset <span class=\"token operator\">=</span> load_dataset<span class=\"token punctuation\">(</span><span class=\"token string\">\"parquet\"</span><span class=\"token punctuation\">,</span> data_files<span class=\"token operator\">=</span><span class=\"token string\">'dataset-resized-64.parquet'</span><span class=\"token punctuation\">,</span> split<span class=\"token operator\">=</span><span class=\"token string\">\"train\"</span><span class=\"token punctuation\">)</span>\ndataset<span class=\"token punctuation\">.</span>set_format<span class=\"token punctuation\">(</span><span class=\"token string\">\"torch\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">show_images</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Given a batch of images x, make a grid and convert to PIL\"\"\"</span>\n    x <span class=\"token operator\">=</span> x <span class=\"token operator\">*</span> <span class=\"token number\">0.5</span> <span class=\"token operator\">+</span> <span class=\"token number\">0.5</span>  <span class=\"token comment\"># Map from (-1, 1) back to (0, 1)</span>\n    grid <span class=\"token operator\">=</span> torchvision<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>make_grid<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    grid_im <span class=\"token operator\">=</span> grid<span class=\"token punctuation\">.</span>detach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cpu<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>permute<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>clip<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">255</span>\n    grid_im <span class=\"token operator\">=</span> Image<span class=\"token punctuation\">.</span>fromarray<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>grid_im<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>uint8<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> grid_im\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">make_grid</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Given a list of PIL images, stack them together into a line for easy viewing\"\"\"</span>\n    output_im <span class=\"token operator\">=</span> Image<span class=\"token punctuation\">.</span>new<span class=\"token punctuation\">(</span><span class=\"token string\">\"RGB\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>size <span class=\"token operator\">*</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> im <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>images<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output_im<span class=\"token punctuation\">.</span>paste<span class=\"token punctuation\">(</span>im<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>size<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">*</span> size<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> output_im\n\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">16</span>\ndataset_resized<span class=\"token punctuation\">.</span>set_format<span class=\"token punctuation\">(</span><span class=\"token string\">\"torch\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Create a dataloader from the dataset to serve up the transformed images in batches</span>\ntrain_dataloader <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>DataLoader<span class=\"token punctuation\">(</span>\n    dataset_resized<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span>batch_size<span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span>\n<span class=\"token punctuation\">)</span>\n\ndevice <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>device<span class=\"token punctuation\">(</span><span class=\"token string\">\"cuda\"</span> <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token string\">\"cpu\"</span><span class=\"token punctuation\">)</span>\nxb <span class=\"token operator\">=</span> <span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">iter</span><span class=\"token punctuation\">(</span>train_dataloader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"images\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"X shape:\"</span><span class=\"token punctuation\">,</span> xb<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">)</span>\nshow_images<span class=\"token punctuation\">(</span>xb<span class=\"token punctuation\">)</span> <span class=\"token comment\">#.resize((8 * 64, 64), resample=Image.NEAREST)</span></code></pre></div>\n<h2 id=\"recognize-faces\" style=\"position:relative;\">Recognize faces<a href=\"#recognize-faces\" aria-label=\"recognize faces permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>Just to avoid manual work. Also how to create unsupervised butt recognition model? Try to use <a href=\"https://arxiv.org/pdf/1706.05274.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">GAN for object detection</a></p>\n<p><a href=\"https://github.com/tkarras/progressive_growing_of_gans\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">code</a></p>\n<h2 id=\"diffusion\" style=\"position:relative;\">Diffusion<a href=\"#diffusion\" aria-label=\"diffusion permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p><a href=\"https://colab.research.google.com/github/huggingface/diffusion-models-class/blob/main/unit1/01_introduction_to_diffusers.ipynb\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">notebook</a></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">conda create <span class=\"token parameter variable\">-n</span> diffusers <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.10</span>\nconda activate diffusers\npip <span class=\"token function\">install</span> matplotlib Pillow datasets diffusers\npip3 <span class=\"token function\">install</span> torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\npip <span class=\"token function\">install</span> notebook\njupyter notebook</code></pre></div>\n<p>Diffusion in Python is slow. Because, well, who would have thought, it does a big portion in Python, not CUDA. Despite Python version is already spicy for my NVIDIA GeForce GTX 1060 (Compute Capability <strong>6.1</strong>), I think that moving everything to C++ is a correct way. <a href=\"https://pytorch.org/tutorials/advanced/cpp_frontend.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">PyTorch C++ API</a></p>\n<p>One main thing, gaussian noise, is what disappointed me in diffusion models. It just a funny toy that surprisingly works. It has no value for neural network research. Restoring/generating images from gray noise? That is not a sign on intellect. It's just an algorithm. And noise is not that important for that idea to work. One can use <a href=\"https://muse-model.github.io/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">masks</a> which will be much faster because noise generation is not fast with software implmentation.</p>\n<p>It's worth noting that PyTorch 2.0 <a href=\"https://pytorch.org/blog/accelerated-generative-diffusion-models/\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">did some improvements</a> for attention layers</p>\n<p>I have some doubts that my model architecture is correct, because even after 560k steps (40 epochs on 14k training pictures) it looks almost like noise.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> diffusers <span class=\"token keyword\">import</span> UNet2DModel\n\nmodel <span class=\"token operator\">=</span> UNet2DModel<span class=\"token punctuation\">(</span>\n    sample_size<span class=\"token operator\">=</span>image_size<span class=\"token punctuation\">,</span>  <span class=\"token comment\"># the target image resolution</span>\n    in_channels<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># the number of input channels, 3 for RGB images</span>\n    out_channels<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># the number of output channels</span>\n    layers_per_block<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># how many ResNet layers to use per UNet block</span>\n    block_out_channels<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># More channels -> more parameters</span>\n    down_block_types<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>\n        <span class=\"token string\">\"DownBlock2D\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># a regular ResNet downsampling block</span>\n        <span class=\"token string\">\"DownBlock2D\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"DownBlock2D\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"AttnDownBlock2D\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># a ResNet downsampling block with spatial self-attention</span>\n        <span class=\"token string\">\"DownBlock2D\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    up_block_types<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>\n        <span class=\"token string\">\"UpBlock2D\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"AttnUpBlock2D\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># a ResNet upsampling block with spatial self-attention</span>\n        <span class=\"token string\">\"UpBlock2D\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"UpBlock2D\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"UpBlock2D\"</span><span class=\"token punctuation\">,</span>  <span class=\"token comment\"># a regular ResNet upsampling block</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"c-code\" style=\"position:relative;\">C++ code<a href=\"#c-code\" aria-label=\"c code permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p><strong>PyTorch C++</strong>: <a href=\"https://pytorch.org/tutorials/advanced/cpp_frontend.html\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Docs</a>, <a href=\"https://github.com/pytorch/examples/tree/main/cpp\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">examples</a></p>\n<h2 id=\"smaller-dataset\" style=\"position:relative;\">Smaller dataset<a href=\"#smaller-dataset\" aria-label=\"smaller dataset permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>I incline to small but coherent datasets. This will make every diffusion model precise in their little purposes. Which means I need to work on my dataset. It has already some categories and I will start to train body part recognition models [using GAN]<a href=\"https://towardsdatascience.com/semi-supervised-learning-with-gans-9f3cb128c5e\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">https://towardsdatascience.com/semi-supervised-learning-with-gans-9f3cb128c5e</a>), but to generate something interesting I need to <a href=\"https://github.com/google/mediapipe/blob/master/docs/solutions/pose.md\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">recognize poses</a> and generate new ones (I saw GAN models can do it). Pose recognition is very helpful for robots anyway. </p>\n<p>That’s how they <a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/file/34ed066df378efacc9b924ec161e7639-Paper.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">can learn new movements</a>, though their bone and “muscle” structure is different. But maybe they can imitate to some degree.</p>\n<p>The images in the STL10 have a lot of variation meaning more \"features\" need to be encoded in the latent space to achieve a good reconstruction. Using a data-set with less variation (and the same latent vector size) should results in a higher quality reconstructed image.</p>\n<p>After CNN try <a href=\"https://thesai.org/Downloads/IJARAI/Volume4No7/Paper_1-A_Minimal_Spiking_Neural_Network_to_Rapidly_Train.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">this approach</a> next.</p>","excerpt":"Initial plan read about crop blur technique in modern datasets. (I think I’ve seen it when I read about Celeb HQ)  crop to faces: recognize…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#initial-plan\">Initial plan</a></p>\n</li>\n<li>\n<p><a href=\"#image-files-into-dataset\">Image files into dataset</a></p>\n</li>\n<li>\n<p><a href=\"#using-dataset-examples\">Using dataset examples</a></p>\n<ul>\n<li><a href=\"#load-and-show-images\">Load and show images</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#recognize-faces\">Recognize faces</a></p>\n</li>\n<li>\n<p><a href=\"#diffusion\">Diffusion</a></p>\n</li>\n<li>\n<p><a href=\"#c-code\">C++ code</a></p>\n</li>\n<li>\n<p><a href=\"#smaller-dataset\">Smaller dataset</a></p>\n</li>\n</ul>","fields":{"socialcard":"gatsby-plugin-social-card/fe68679e-fb93-5434-b9d2-b7bd9f568fdf.jpg"},"frontmatter":{"date":"July 17, 2023","published":"July 17, 2023","lastModified":"August 07, 2023","title":"My Small Training Dataset","subtitle":null,"section":null,"draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/my-dataset.md","url":"/ai/my-dataset","next":{"excerpt":"All ART models\nFresh article where Grossberg critisicizes back propagation and deep learning. And related interview that planned to be a…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/adaptive-resonance-theory.md","frontmatter":{"title":"Adaptive Resonance Theory","date":"2023-07-23T00:00:00.000Z","topic":true,"article":null},"id":"0ffc2284-80ea-5e7b-af68-996280aef327"},"previous":{"excerpt":"Questions Are embeddings required for any type of data? Why sin/cos? What stacks add to the whole picture? How are they different? Why…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/the-smallest-transformer.md","frontmatter":{"title":"The smallest Transformer","date":"2023-06-03T00:00:00.000Z","topic":null,"article":"quest"},"id":"bf0eddd7-c885-5815-8d65-8ba8c9bf0651"},"recentArticles":[{"excerpt":"BAM can link together data of different types. Associations...  From one side the model requires to use bipolar patterns - arrays of -1 and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/bidirectional-associative-memories.md","frontmatter":{"title":"Bidirectional Associative Memories","date":null,"topic":true,"article":null},"id":"3ae9ac87-4c8b-5f18-8f19-ee1091111f95"},{"excerpt":"Phenotypic variation of transcriptomic cell types in mouse motor cortex (paper). Scientist got neurons from different layers and regions and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/brain-map.md","frontmatter":{"title":"Brain map","date":null,"topic":true,"article":null},"id":"f4152a9b-6747-5178-aea3-0de2e3f70b04"},{"excerpt":"Neural networks with biologically plausible accounts of neurogenesis they start with a minimal topology (just input and output unit) and…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cascade-correlation-neural-networks.md","frontmatter":{"title":"Cascade Correlation Neural Networks","date":null,"topic":true,"article":null},"id":"1ba88be8-cdba-50c0-a9ba-c4a082ef60e7"},{"excerpt":"ACT-R CLARION LIDA Soar (code)","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/cognitive-architecture.md","frontmatter":{"title":"Cognitive Architecture","date":null,"topic":true,"article":null},"id":"1acc6cfc-d238-53b6-aeed-1207dd3b1d89"},{"excerpt":"Main paper PDF stacking lstms https://stats.stackexchange.com/questions/163304/what-are-the-advantages-of-stacking-multiple-lstms intro to…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/ai/long-short-term-memory.md","frontmatter":{"title":"Long Short-Term Memory","date":null,"topic":true,"article":null},"id":"a677bfb4-f49d-559c-8957-86db6eb41bda"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}