{"componentChunkName":"component---src-templates-blog-template-js","path":"/science/cycle-gan-pixelation","result":{"data":{"markdownRemark":{"html":"<h2 id=\"️-work-in-progress-️\" style=\"position:relative;\">⚠️ Work in progress ⚠️<a href=\"#%EF%B8%8F-work-in-progress-%EF%B8%8F\" aria-label=\"️ work in progress ️ permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<h2 id=\"load-images\" style=\"position:relative;\">Load images<a href=\"#load-images\" aria-label=\"load images permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>I'm using TensorFlow and I need to scale black and white image from 512x512 pixels stored in <code class=\"language-text\">tf.Tensor</code> to 128x96 and add pixelation effect to the image using.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token comment\"># Load the image as a tf.Tensor</span>\nimage <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span>read_file<span class=\"token punctuation\">(</span><span class=\"token string\">'path/to/image.jpg'</span><span class=\"token punctuation\">)</span>\nimage <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>decode_jpeg<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># assuming the image is black and white</span>\n\n<span class=\"token comment\"># Scale the image to 128x96 pixels</span>\nimage <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>resize<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">96</span><span class=\"token punctuation\">,</span> <span class=\"token number\">128</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Add pixelation effect</span>\nblock_size <span class=\"token operator\">=</span> <span class=\"token number\">8</span>\nimage <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>avg_pool<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> ksize<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>block_size<span class=\"token punctuation\">,</span> block_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> strides<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>block_size<span class=\"token punctuation\">,</span> block_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'VALID'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Cast the image back to uint8 data type and save it</span>\nimage <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>uint8<span class=\"token punctuation\">)</span>\nimage <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>image<span class=\"token punctuation\">.</span>encode_jpeg<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span>\ntf<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span>write_file<span class=\"token punctuation\">(</span><span class=\"token string\">'path/to/scaled_and_pixelated_image.jpg'</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span></code></pre></div>\n<p>In this code, we first load the image as a <code class=\"language-text\">tf.Tensor</code> using <code class=\"language-text\">tf.io.read_file</code> and <code class=\"language-text\">tf.image.decode_jpeg</code> functions. We then use the <code class=\"language-text\">tf.image.resize</code> function to scale the image to 128x96 pixels. Finally, we apply the pixelation effect using the <code class=\"language-text\">tf.nn.avg_pool</code> function with a block size of 8x8 pixels.</p>\n<p>Note that the <code class=\"language-text\">tf.nn.avg_pool</code> function returns a <code class=\"language-text\">float32</code> tensor, so we need to cast it back to <code class=\"language-text\">uint8</code> data type before saving the image using <code class=\"language-text\">tf.image.encode_jpeg</code> and <code class=\"language-text\">tf.io.write_file</code> functions.</p>\n<h2 id=\"encoder-decoder\" style=\"position:relative;\">Encoder-decoder<a href=\"#encoder-decoder\" aria-label=\"encoder decoder permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>The encoder network is used to extract high-level features from the input data and convert it into a compressed representation that retains the most important information from the input. The encoder typically consists of several convolutional layers that are used to reduce the spatial dimensionality of the input data while increasing its depth.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 516px; flex:1.2734375;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3d6074107d66ab82387cc1522b6b171b/75dcb/generator-encoder-output.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 78.52760736196319%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAIAAACZeshMAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAC+klEQVR42mWT2U8TQRzH+8fIixJbsATliBANiURBRUmQYJUrEBJOSanQQunBYQVK9EmfjD4YOR5450GN8QUThYhAQgs99ujs7uzdbrutvy0ogt+dnUx25zu/z35n1pRJ62pSU1RNkiWMeQGLDMtyHMcyLMMwkiynUinVUBIEY+NOpbT8Q5Ou61o6k9FzDIMOw5FEjNnb293b3d3d2dn+tR2NxgRBUBRVlhUYYMzxWGAwi3gkK7Ip90e8KERJkqLZGEVGCTJOUgmEiDgBCKqSFEUJcGiaRhSK00QURYDUMGfhyuWwxIfpSJyi4iS5HwqFwmFJMpihgiAJsiznqQE7qaU0aAb238qAFIvFiBh5cBDe3w8dhMNQB2PMYIbmaF7gYbaSFywH3Smzqqg8z8MSYEAIQSlIIp1OZyAR6E5Ly8uU0/VsOg0tk8kkVdXINpmUJEkzYjz2wCpZPQuzU8fSIGaoZ8pqqYwo6IoMb2BzRAHLkphUZcwwEC42to3lOQ4gRQxgnChB6jyAG+Yj5mzWyGzrIDL0askRWBmZWR58szK4tDTwbuXp4oextbeDr1eevFwdfr469HJ5au09KwonZmCHfv3bVkHzxIX6SfMD5zmbu6DZc75uvLjGYekZPdc1YW6wV7b2Xah1lvR6Iyw6a/688dPaMmvtDJS2zVqhPZ6t6posHfFYhgLW9pl6+3Db6EBN8/i1vvlDjj1r/vR1s6jTW1Y3U9nkL+n2lvRMXW7yFQ7PmjueX7V5bjhG7/S7qrpd1U/mI+hfc/6b179slrucFTZfZf1UeaO7tMlXds9X1uazjE1XtPiqH09Y/X5L90ytazqKmP/MH78X3/dffOi3PJgqHPVe6vAW3fZY7K7itklLr6e633Gl3W1+NFnV8SxKsmfT3tj6cac/2OgO3HIs3rQH7w4t2Nz+6wvBOvuLWudigzPY4Jq7Ox5oHZsjKP7EnMsfb/g1E3D8JQ4hLhHj4nRCEBmCoJHER0IUi3kSEWxCjJDU0SH5DSH3/tXAACybAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Output from encoder of the GAN generator\"\n        title=\"\"\n        src=\"/static/3d6074107d66ab82387cc1522b6b171b/75dcb/generator-encoder-output.png\"\n        srcset=\"/static/3d6074107d66ab82387cc1522b6b171b/222b7/generator-encoder-output.png 163w,\n/static/3d6074107d66ab82387cc1522b6b171b/ff46a/generator-encoder-output.png 325w,\n/static/3d6074107d66ab82387cc1522b6b171b/75dcb/generator-encoder-output.png 516w\"\n        sizes=\"(max-width: 516px) 100vw, 516px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>The decoder network is used to take the compressed representation generated by the encoder and reconstruct the original input data. The decoder typically consists of several upsampling layers that increase the spatial dimensionality of the compressed representation while decreasing its depth.</p>\n<p>The encoder-decoder architecture is often referred to as an \"autoencoder\". The term \"autoencoder\" comes from the fact that the encoder and decoder are trained together, with the goal of minimizing the difference between the original input and the reconstructed output.</p>\n<h2 id=\"discriminator\" style=\"position:relative;\">Discriminator<a href=\"#discriminator\" aria-label=\"discriminator permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<p>How to design a discriminator for U-Net architecture when input images have size is 256x256, but output size is 128x96?</p>\n<p>We will use a patch-based discriminator. This type of discriminator takes small patches from both the input and output images and classifies them as real or fake.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">build_discriminator</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Input layer for the original 256x256 image</span>\n    input_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Downsample the original image to 128x96</span>\n    downsampled_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strides<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>input_image<span class=\"token punctuation\">)</span>\n    downsampled_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LeakyReLU<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>downsampled_image<span class=\"token punctuation\">)</span>\n    downsampled_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strides<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>downsampled_image<span class=\"token punctuation\">)</span>\n    downsampled_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>downsampled_image<span class=\"token punctuation\">)</span>\n    downsampled_image <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LeakyReLU<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>downsampled_image<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Input layer for the generator output</span>\n    generated_output <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Input<span class=\"token punctuation\">(</span>shape<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> <span class=\"token number\">96</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Concatenate the downsampled original image and the generated output</span>\n    combined_images <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>concatenate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>downsampled_image<span class=\"token punctuation\">,</span> generated_output<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Convolutional layers</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">256</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strides<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>combined_images<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LeakyReLU<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Conv2D<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> strides<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> padding<span class=\"token operator\">=</span><span class=\"token string\">'same'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>BatchNormalization<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>LeakyReLU<span class=\"token punctuation\">(</span>alpha<span class=\"token operator\">=</span><span class=\"token number\">0.2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Flatten<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>layers<span class=\"token punctuation\">.</span>Dense<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Create a model with the input and output layers</span>\n    model <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>Model<span class=\"token punctuation\">(</span>inputs<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>input_image<span class=\"token punctuation\">,</span> generated_output<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> outputs<span class=\"token operator\">=</span>x<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> model</code></pre></div>\n<p>The distinction between L1 and L2 regularization is that L1's additions to cost correspond to the absolute value of parameter sizes, whereas L2's additions correspond to the <em>square</em> of these. The net effect of this is that L1 regularization tends to lead to the inclusion of a smaller number of larger-sized parameters in the model, while L2 regularization tends to lead to the inclusion of a larger number of smaller-sized parameters. [1]</p>\n<p><strong>Dropout</strong> simply pretends that a randomly selected proportion of the neurons in each layer don't exist during each round of training.</p>\n<p>[1] - Jon Krohn - Deep Learning Illustrated: A Visual, Interactive Guide to Artificial Intelligence</p>\n<h2 id=\"reference\" style=\"position:relative;\">Reference<a href=\"#reference\" aria-label=\"reference permalink\" class=\"with-anchor after\"><svg aria-hidden=\"true\" height=\"20\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"20\">\n                <path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3\n                3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3\n                  9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64\n                  1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\">\n                </path>\n                </svg></a></h2>\n<ul>\n<li>Original StyleGAN - (2017) <a href=\"https://arxiv.org/pdf/1705.06830.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Exploring the structure of a real-time, arbitrary neural artistic stylization network</a>. TensorFlow <a href=\"https://www.tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">tutorial</a></li>\n<li>How to get good quiality? - BigGAN - (2019) <a href=\"https://arxiv.org/pdf/1809.11096.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Large scale GAN training for hide fidelity natural image synthesis</a></li>\n<li>Unpaired training - CycleGAN (2020) <a href=\"https://arxiv.org/pdf/1703.10593.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a></li>\n<li>U-Net archetecture with encoder-decoder - (2015) <a href=\"https://arxiv.org/pdf/1505.04597.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a></li>\n<li>Conditional GAN  uses PatchGAN to fight the blur in generator - (2018) <a href=\"https://arxiv.org/pdf/1611.07004.pdf\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Image-to-Image Translation with Conditional Adversarial Networks</a></li>\n<li><a href=\"https://inikolaeva.medium.com/make-pixel-art-in-seconds-with-machine-learning-e1b1974ba572\" target=\"_blank\" rel=\"external nofollow noopener noreferrer\">Torch example</a> and ready to use models for making pixel art</li>\n</ul>","excerpt":"⚠️ Work in progress ⚠️ Load images I'm using TensorFlow and I need to scale black and white image from 512x512 pixels stored in  to 128x9…","tableOfContents":"<ul>\n<li><a href=\"#%EF%B8%8F-work-in-progress-%EF%B8%8F\">⚠️ Work in progress ⚠️</a></li>\n<li><a href=\"#load-images\">Load images</a></li>\n<li><a href=\"#encoder-decoder\">Encoder-decoder</a></li>\n<li><a href=\"#discriminator\">Discriminator</a></li>\n<li><a href=\"#reference\">Reference</a></li>\n</ul>","fields":{"socialcard":"gatsby-plugin-social-card/4ba80532-4f51-5341-835c-2b57b4537a56.jpg"},"frontmatter":{"date":"April 11, 2023","published":"April 11, 2023","lastModified":"April 11, 2023","title":"Pixelate images with CycleGAN","subtitle":null,"section":null,"draft":null,"developing":null,"buttonText":null,"buttonLink":null,"secondButtonText":null,"secondButtonLink":null,"featuredImage":null}}},"pageContext":{"showLikes":true,"absolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/cycle-gan-pixelation.md","url":"/science/cycle-gan-pixelation","next":{"excerpt":"You can find this in many scientific papers, common phrases indicating that the proper explanation is skipped, here sorted in the growing…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/as-always-no-explanation.md","frontmatter":{"title":"As always - no explanation","date":"2023-06-04T00:00:00.000Z","topic":null,"article":null},"id":"cbdf4071-1dc6-521c-b9eb-e67b0840a8fa"},"previous":{"excerpt":"First, I got carried away with researching what a Dyck language is. I was damn certain that some geeks already released an online service…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/dyck-language-converter.md","frontmatter":{"title":"Dyck language converter","date":"2023-02-02T00:00:00.000Z","topic":null,"article":null},"id":"97734e6a-4bae-55ee-9de1-0efd1ff0bfdd"},"recentArticles":[{"excerpt":"Infinite zoom Yes, let's make an infinite zoom in real time in the browser using WebGL and shaders. Limited precision of floating point…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/mandelbrot.md","frontmatter":{"title":"Mandelbrot","date":"2025-08-03T00:00:00.000Z","topic":null,"article":null},"id":"50df8845-e3c8-53e2-889f-30490e52a353"},{"excerpt":"Today I came up with another weird combination. How can I use Reed-Solomon error correction on directed acyclic graph? In another words…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/reed-solomon-codes-in-neural-networks.md","frontmatter":{"title":"Reed Solomon Codes in Neural Networks","date":"2023-08-16T00:00:00.000Z","topic":null,"article":null},"id":"5fa2845a-3361-5ab4-bc19-d89c6598f044"},{"excerpt":"You can find this in many scientific papers, common phrases indicating that the proper explanation is skipped, here sorted in the growing…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/as-always-no-explanation.md","frontmatter":{"title":"As always - no explanation","date":"2023-06-04T00:00:00.000Z","topic":null,"article":null},"id":"cbdf4071-1dc6-521c-b9eb-e67b0840a8fa"},{"excerpt":"⚠️ Work in progress ⚠️ Load images I'm using TensorFlow and I need to scale black and white image from 512x512 pixels stored in  to 128x9…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/cycle-gan-pixelation.md","frontmatter":{"title":"Pixelate images with CycleGAN","date":"2023-04-11T00:00:00.000Z","topic":null,"article":null},"id":"4ba80532-4f51-5341-835c-2b57b4537a56"},{"excerpt":"First, I got carried away with researching what a Dyck language is. I was damn certain that some geeks already released an online service…","fileAbsolutePath":"/home/runner/work/mikolasan.github.io/mikolasan.github.io/src/markdown/science/dyck-language-converter.md","frontmatter":{"title":"Dyck language converter","date":"2023-02-02T00:00:00.000Z","topic":null,"article":null},"id":"97734e6a-4bae-55ee-9de1-0efd1ff0bfdd"}]}},"staticQueryHashes":["2961657013","447685113"],"slicesMap":{}}