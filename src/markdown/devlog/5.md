---
title: "Devlog #5"
date: 2023-06-21
published: 2023-06-21
lastModified: 2023-06-21
---

> Something interesting always starts with something very stupid

What do people find interesting about robots?

- emotional connection, interactivity
- technological fascination, novelty

People would love to explore capabilities of robots. I guess many designs provide only limited amount of capabilities and its combinations. But is there a way to make design that offers unlimited amount of combinations?

- modular design
- programmability
- learn from its environment (with the help of machine learning)
- integrations
- interconnectivity (unlock functionality with more than one robot)

If I create a Tamagotchi-like robot, will it be a hit?

Tamagotchi, a virtual pet simulation game, became a significant cultural phenomenon in the 1990s, capturing the attention and fascination of millions of people worldwide. While replicating the exact success of Tamagotchi is not possible and copying someone's product is never what makers do, but we caan draw inspiration from Tamagotchi anyway.

- Find a gap in the market
- Focus on immersive and engaging user experience
- Make it simple, simple even for casual users
- Plan for content updates, replayability
- Challenges and achievements, leaderboard (not always applicable)
- Build with quality materials (sometimes just this brings joy)
- Do not forget about solid marketing strategy. The goal must be clear
- Gather early feedback


Also feasable to make a series of models that will stimulate people to get a full collection. For example, I will do different robot designs: one will look like a viking, another like a cat. But what collective activities this will imply?

What is the example of decision-making in robotics?

Autonomous navigation is a good example of decision-making. But it’s unclear why the robot needs to follow the path? What’s his goal?

- delivery
- agricultural
- exploration (underwater, planetary surface, territory after disaster)

I like the agricultural robot example. So let’s assume the robot needs to sow, water the fields, locate and remove weeds, harvest. Let’s start with the basics: how does it know when to do all these tasks? I’d apply transfer learning technique. This way we can train the robot on one specie like potato and it will figure out how to do similar things on tomatoes and strawberries and such. With trial and error of course, but that’s where the following techniques will help. 

- schedule based on agricultural best practices based on a crop type, growth stage, weather conditions, and regional guidelines
- sensor-based monitoring such as soil moisture, temperature, humidity, and light
- computer vision to identify the growth stage and health by analyzing leaf size, color, fruit development
- find patterns in historical data with machine learning


So how this transfer learning is implemented is a question. 
Can we load the robot with knowledge every agronomist must know? It will be semantic knowledge and we need to find a way to use it in neural networks. LLMs trained on big corpse of knowledge. And if some general purpose models available online not specialize on agriculture, but they can be fine-tuned on agriculturist’s expertise. And technically LLMs are neural networks, thus we don’t need to worry about transforming semantic data into neural features. The only problem is the training method of Transformers. This relates to other neural networks as well. The gradient descent is very slow process. Spiking networks more efficient and less resource intensive. Will it be applied to Transformers? How about one-shot training? What one-shot learning techniques will be more suitable for Transformers? Is there a method that will not require data augmentation and in case of one-shot learning the training process will end after one sample presented to the model?

**Metric Learning**. Metric learning techniques attempt to create embeddings that bring similar examples closer together in the embedding space while pushing dissimilar examples further apart. For example, using the Triplet Loss. We will need an anchor sample, positive and negative sample.

TripletLoss = max(0, distance(anchor, negative) - distance(anchor, positive) + margin)

**Memory-Augmented Neural Networks**. MANNs use the memory to store information from previously seen examples and then access this stored knowledge to make predictions on new, unseen examples, even with limited data. One popular memory-augmented neural network architecture is the "Neural Turing Machine" (NTM), introduced by Alex Graves et al. in 2014.

The big problem with open source world is that some cool projects stay in the shadow. No one notices it if no one mentions it, and if the maintainer is not a public person. Also when it's missing live ecosystem.


release plan

- Order components: servo, DC, brushless motors, sensors, battery, logic board
- Manufacture PCB for motor/power/sensor board
- Design 3D body
- Face animations on LCD

Let’s sum up what it can do.



## Features 

- Cute
- Talk jokes 
- Finds users face (camera, IR sensor)
- Detects emotions 
- Keep up the conversation 
- Recognizes speech 
- Voice generation 
- movements (maybe just waving or driving on a flat surface )

## Collectables

different abilities combine for variation


## More realistic plan

Create a hexapod design, give 3d parts for free, publish settings for slicer programs, recommend the best colors for filament, affiliated links to purchase filament.