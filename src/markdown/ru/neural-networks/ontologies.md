---
path: "/ru/neural-networks/ontologies"
date: "2020-07-11"
title: "Онтологии"
language: "ru"
draft: true
published: 2021-10-13
lastModified: 2022-07-31
---

## Определение

Когда я учился в университете то нашел научного руководителя, который занимался интересным направлением - [онтологическим анализом данных](http://math.nsc.ru/AP/ScientificDiscovery/pages/Theory_rus.html). Мое первое впечатление об этом направлении состояло в наличии некоторого алгоритма, который позволяет извлекать мета информацию из любого объекта будь это текст или картинка. По моим представлениям этот алгоритм может создать представление о предметной области и сохранить это в базе данных. Эти данные мы и назовем онтологией. При этом меня восхищал факт, что из вводных данных мы извлекаем зависимости не заданные явно и в последствии можем даже дополнять данные пропущеннымя деталями. Та информация, которая неявно присутствует в них я назвал выше мета информацией. 

Но что это за неявные зависимости? Будет ли это вероятностная зависимость, которая определяется методами статистики и предсказание строится на линейной регрессии? Это кстати, чем профессия Data Scientist занимается, не более чем современное название статистика.

Но нам нужны онтологии. Собственно как они выглядят и как этот "алгоритм" там работает.

Согласно [посленей статьи](http://www.math.nsc.ru/AP/ScientificDiscovery/PDF/relational_methodology_paper.pdf) по этому направлению онтологию задаем мы, чтобы алгоритм мог правильно интерпретировать вводные данные. Т.е. мы имеем онтологию априори, а вовсе не извлекаем ее.

>  any KDD&DM method explic-itly or implicitly assume ... ontology  of  particular  KDD&DM  method  (including  a  language)  to  manipulate  and  interpret data and results

## Входные данные

Первое разочарование в том, что нет такого алгоритма, который бы самостоятльено разбирался в формате данных и смог бы понять любой поток байтов. То есть неважно если это структурированная таблица в CSV файле, абзацы текста в TXT файле, картинка в формате PNG или JPEG - это будут разные алгоритмы. Более того, даже если мы остановимся на подготовленных CSV файлах, они могут содержать данные с пропусками, с которыми не каждый алгоритм может работать.

Здесь возникает первое искуственное ограничение - мы выбираем формат данных, подготавливаем структуру и фиксируем алгоритм подчиняться это структуре. В дальнейшем мы, возможно, станем подгонять данные для новых задач под определенную структуру только потому, что алгоритм от этого лучше работает. 

С другой стороны, если алгоритм применим к разным форматам данных без изменений основной логики программы, то ограничение на формат данных можно будет снять позже.

## Хитрая терминология

Подход описанный Витяевым извлекает знания из данных и решает задачи интеллектуального анализа данных. 

?? Определения знаний
?? Примеры задач интеллектуального анализа данных


